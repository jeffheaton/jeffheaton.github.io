<!DOCTYPE html>
<html>
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="utf-8">
  
  <title>Overview of Keras/TensorFlow Basic Operations | Heaton Research</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="I in the process of updating my deep learning course and books to make use of Keras.  This posting contains some of the basic examples that I put together. This post is not meant to be an introduction">
<meta property="og:type" content="article">
<meta property="og:title" content="Overview of Keras&#x2F;TensorFlow Basic Operations">
<meta property="og:url" content="https://www.heatonresearch.com/2017/07/22/keras-getting-started.html">
<meta property="og:site_name" content="Heaton Research">
<meta property="og:description" content="I in the process of updating my deep learning course and books to make use of Keras.  This posting contains some of the basic examples that I put together. This post is not meant to be an introduction">
<meta property="og:locale">
<meta property="og:image" content="https://www.heatonresearch.com/images/content/keras_mnist_7.png">
<meta property="article:published_time" content="2017-07-22T12:00:00.000Z">
<meta property="article:modified_time" content="2025-01-20T12:40:01.953Z">
<meta property="article:author" content="Jeff Heaton">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://www.heatonresearch.com/images/content/keras_mnist_7.png">
<meta name="twitter:creator" content="@jeffheaton">
  
    <link rel="alternate" href="/atom.xml" title="Heaton Research" type="application/atom+xml">
  
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/css/bootstrap.min.css" integrity="sha384-1q8mTJOASx8j1Au+a5WDVnPi2lkFfwwEAa8hDDdjZlpLegxhjVME1fgjWPGmkzs7" crossorigin="anonymous">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" integrity="sha384-XdYbMnZ/QjLh6iI4ogqCTaIjrFk87ip+ekIjefZch0Y+PvJ8CDYtEs1ipDmPorQ+" crossorigin="anonymous">

  
  

  

  
<link rel="stylesheet" href="/css/styles.css">

  
<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-5393865-1', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->


  <script data-ad-client="ca-pub-6846576724383320" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
<!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.4.2"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><nav class="navbar navbar-inverse">
  <div class="container">
    <!-- Brand and toggle get grouped for better mobile display -->
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#main-menu-navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      
        <a class="navbar-brand" href="/">Heaton Research</a>
      
    </div>

    <!-- Collect the nav links, forms, and other content for toggling -->
    <div class="collapse navbar-collapse" id="main-menu-navbar">
      <ul class="nav navbar-nav">
        
          <li><a class=""
                 href="/about/">About</a></li>
        
          <li><a class=""
                 href="/jeff_heaton_projects.html">Projects</a></li>
        
          <li><a class=""
                 href="/book/">Books</a></li>
        
          <li><a class=""
                 href="/contact.html">Contact</a></li>
        
          <li><a class=""
                 href="/support.html">Support Me</a></li>
        
          <li><a class=""
                 href="/archives/">Archives</a></li>
        
      </ul>

      <!--
      <ul class="nav navbar-nav navbar-right">
        
          <li><a href="/atom.xml" title="RSS Feed"><i class="fa fa-rss"></i></a></li>
        
      </ul>
      -->
    </div><!-- /.navbar-collapse -->
  </div><!-- /.container-fluid -->
</nav>

  <div class="container">
    <div class="blog-header">
  <h1 class="blog-title">Heaton Research</h1>
  
</div>

<div class="row">
    <div class="col-sm-8 blog-main">
      <article id="post-keras-getting-started" class="article article-type-post" itemscope itemprop="blogPost">

  <header class="article-header">
    
  
    <h1 class="article-title" itemprop="name">
      Overview of Keras/TensorFlow Basic Operations
    </h1>
  


  </header>

  <div class="article-meta">
    <div class="article-datetime">
  <a href="/2017/07/22/keras-getting-started.html" class="article-date"><time datetime="2017-07-22T12:00:00.000Z" itemprop="datePublished">2017-07-22</time></a>
</div>

    
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/ai/">ai</a>
  </div>


  </div>
  <div class="article-inner">

    <div class="article-entry" itemprop="articleBody">
      
        <p>I in the process of updating my deep learning <a target="_blank" rel="noopener" href="https://sites.wustl.edu/jeffheaton/t81-558/">course</a> and <a target="_blank" rel="noopener" href="http://www.aifh.org/">books</a> to make use of <a target="_blank" rel="noopener" href="https://keras.io/">Keras</a>.  This posting contains some of the basic examples that I put together. This post is not meant to be an introduction to neural networks in general.  For such an introduction, refer to either my <a href="/book/">books</a> or <a href="http://www.heatonresearch.com/content/non-mathematical-introduction-using-neural-networks">this article</a>.</p>
<p>I will expand on these examples greatly for both the book and course.  The basic neural network operations that I needed were:</p>
<ul>
<li>Simple Regression</li>
<li>Regression Early Stopping</li>
<li>Simple Classification</li>
<li>Classification Early Stopping</li>
<li>Deep Neural Networks w/Dropout and Other Regularization</li>
<li>Convolutional Neural Networks</li>
<li>LSTM Neural Networks</li>
<li>Loading/Saving Neural Networks</li>
</ul>
<p>These are some of the most basic operations that I need to perform when working with a new neural network package.  This provides me with a sort of Rosetta Stone for a new neural network package.  Once I have these operations, I can more easily create additional examples that are more complex.</p>
<p>The first thing to check is what versions you have of the required packages:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> sklearn <span class="keyword">as</span> sk</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Tensor Flow Version: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(tf.__version__))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Keras Version: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(keras.__version__))</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Python &#123;&#125;&quot;</span>.<span class="built_in">format</span>(sys.version))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Pandas &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(pd.__version__))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Scikit-Learn &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(sk.__version__))</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Tensor Flow Version: 1.0.0</span><br><span class="line">Keras Version: 2.0.6</span><br><span class="line"></span><br><span class="line">Python 3.5.2 |Continuum Analytics, Inc.| (default, Jul  5 2016, 11:41:13) [MSC v.1900 64 bit (AMD64)]</span><br><span class="line">Pandas 0.19.2</span><br><span class="line">Scikit-Learn 0.18.1</span><br></pre></td></tr></table></figure>

<p>The following functions are from my set of <a target="_blank" rel="noopener" href="https://github.com/jeffheaton/t81_558_deep_learning/blob/master/jeffs_helpful.ipynb">helpful functions</a> that I created for my class and use in many of my <a target="_blank" rel="noopener" href="http://www.aifh.org/">books</a>:  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> preprocessing</span><br><span class="line"></span><br><span class="line"><span class="comment"># Encode text values to dummy variables(i.e. [1,0,0],[0,1,0],[0,0,1] for red,green,blue)</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode_text_dummy</span>(<span class="params">df, name</span>):</span></span><br><span class="line">    dummies = pd.get_dummies(df[name])</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> dummies.columns:</span><br><span class="line">        dummy_name = <span class="string">&quot;&#123;&#125;-&#123;&#125;&quot;</span>.<span class="built_in">format</span>(name, x)</span><br><span class="line">        df[dummy_name] = dummies[x]</span><br><span class="line">    df.drop(name, axis=<span class="number">1</span>, inplace=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Encode text values to indexes(i.e. [1],[2],[3] for red,green,blue).</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">encode_text_index</span>(<span class="params">df, name</span>):</span></span><br><span class="line">    le = preprocessing.LabelEncoder()</span><br><span class="line">    df[name] = le.fit_transform(df[name])</span><br><span class="line">    <span class="keyword">return</span> le.classes_</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert all missing values in the specified column to the median</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">missing_median</span>(<span class="params">df, name</span>):</span></span><br><span class="line">    med = df[name].median()</span><br><span class="line">    df[name] = df[name].fillna(med)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert a Pandas dataframe to the x,y inputs that TensorFlow needs</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">to_xy</span>(<span class="params">df, target</span>):</span></span><br><span class="line">    result = []</span><br><span class="line">    <span class="keyword">for</span> x <span class="keyword">in</span> df.columns:</span><br><span class="line">        <span class="keyword">if</span> x != target:</span><br><span class="line">            result.append(x)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># find out the type of the target column.  Is it really this hard? :(</span></span><br><span class="line">    target_type = df[target].dtypes</span><br><span class="line">    target_type = target_type[<span class="number">0</span>] <span class="keyword">if</span> <span class="built_in">hasattr</span>(target_type, <span class="string">&#x27;__iter__&#x27;</span>) <span class="keyword">else</span> target_type</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Encode to int for classification, float otherwise. TensorFlow likes 32 bits.</span></span><br><span class="line">    <span class="keyword">if</span> target_type <span class="keyword">in</span> (np.int64, np.int32):</span><br><span class="line">        <span class="comment"># Classification</span></span><br><span class="line">        dummies = pd.get_dummies(df[target])</span><br><span class="line">        <span class="keyword">return</span> df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="comment"># Regression</span></span><br><span class="line">        <span class="keyword">return</span> df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="Simple-Regression"><a href="#Simple-Regression" class="headerlink" title="Simple Regression"></a>Simple Regression</h2><p>Regression is where a neural network accepts several values (predictors) and produces a prediction that is numeric.  In this simple example we attempt to predict the miles per gallon (MPG) of several cars based on characteristics of those cars.  Several parameters and used below and described here.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://keras.io/losses/">Losses Supported by Keras</a><ul>
<li>Typically use <strong>mean_squared_error</strong> for regression (the square root of mean square error is root mean square error(RMSE)).</li>
<li>and for classification use: <strong>binary_crossentropy</strong> for 2 classes, <strong>categorical_crossentropy</strong> for more than 2 classes.</li>
</ul>
</li>
<li><a target="_blank" rel="noopener" href="https://keras.io/initializers/">kernel_initializer supported by Keras</a> - Species how the weights of are randomized.</li>
<li><a target="_blank" rel="noopener" href="https://keras.io/activations/">activation</a> - Usually relu or softmax will be used.</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Activation</span><br><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"></span><br><span class="line">url=<span class="string">&quot;https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/data/auto-mpg.csv&quot;</span></span><br><span class="line">df=pd.read_csv(io.StringIO(requests.get(url).content.decode(<span class="string">&#x27;utf-8&#x27;</span>)),na_values=[<span class="string">&#x27;NA&#x27;</span>,<span class="string">&#x27;?&#x27;</span>])</span><br><span class="line"></span><br><span class="line">cars = df[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">df.drop(<span class="string">&#x27;name&#x27;</span>,<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">missing_median(df, <span class="string">&#x27;horsepower&#x27;</span>)</span><br><span class="line">x,y = to_xy(df,<span class="string">&quot;mpg&quot;</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">10</span>, input_dim=x.shape[<span class="number">1</span>], activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">&#x27;normal&#x27;</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mean_squared_error&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model.fit(x,y,verbose=<span class="number">2</span>,epochs=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/100</span><br><span class="line">0s - loss: 2240.8034</span><br><span class="line">Epoch 2/100</span><br><span class="line">0s - loss: 1469.8520</span><br><span class="line">Epoch 3/100</span><br><span class="line">0s - loss: 1038.2052</span><br><span class="line">Epoch 4/100</span><br><span class="line">0s - loss: 820.4976</span><br><span class="line">Epoch 5/100</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">0s - loss: 560.3524</span><br><span class="line">Epoch 99/100</span><br><span class="line">0s - loss: 559.7951</span><br><span class="line">Epoch 100/100</span><br><span class="line">0s - loss: 559.2341</span><br><span class="line">&lt;keras.callbacks.History at 0x2263d8cc518&gt;</span><br></pre></td></tr></table></figure>

<p>Now that the neural network is trained, we will test how good it is and perform some sample predictions.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">pred = model.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Measure RMSE error.  RMSE is common for regression.</span></span><br><span class="line">score = np.sqrt(metrics.mean_squared_error(pred,y))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Final score (RMSE): &#123;&#125;&quot;</span>.<span class="built_in">format</span>(score))</span><br><span class="line"></span><br><span class="line"><span class="comment"># Sample predictions</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;&#123;&#125;. Car name: &#123;&#125;, MPG: &#123;&#125;, predicted MPG: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(i+<span class="number">1</span>,cars[i],y[i],pred[i]))</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Final score (RMSE): 3.494112253189087</span><br><span class="line">1. Car name: chevrolet chevelle malibu, MPG: [ 18.], predicted MPG: [ 14.94231319]</span><br><span class="line">2. Car name: buick skylark 320, MPG: [ 15.], predicted MPG: [ 14.08107567]</span><br><span class="line">3. Car name: plymouth satellite, MPG: [ 18.], predicted MPG: [ 15.15124226]</span><br><span class="line">4. Car name: amc rebel sst, MPG: [ 16.], predicted MPG: [ 15.84413433]</span><br><span class="line">5. Car name: ford torino, MPG: [ 17.], predicted MPG: [ 15.11468124]</span><br><span class="line">6. Car name: ford galaxie 500, MPG: [ 15.], predicted MPG: [ 10.48310184]</span><br><span class="line">7. Car name: chevrolet impala, MPG: [ 14.], predicted MPG: [ 10.11642265]</span><br><span class="line">8. Car name: plymouth fury iii, MPG: [ 14.], predicted MPG: [ 10.33946323]</span><br><span class="line">9. Car name: pontiac catalina, MPG: [ 14.], predicted MPG: [ 10.317276]</span><br><span class="line">10. Car name: amc ambassador dpl, MPG: [ 15.], predicted MPG: [ 12.37194347]</span><br></pre></td></tr></table></figure>

<h2 id="Regression-Early-Stop"><a href="#Regression-Early-Stop" class="headerlink" title="Regression (Early Stop)"></a>Regression (Early Stop)</h2><p>Early stopping sets aside a part of the data to be used to validate the neural<br>network.  The neural network is trained with the training data and validated<br>with the validation data.  Once the error no longer improves on the validation<br>set, the training stops.  This prevents the neural network from <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Activation</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"></span><br><span class="line">url=<span class="string">&quot;https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/data/auto-mpg.csv&quot;</span></span><br><span class="line">df=pd.read_csv(io.StringIO(requests.get(url).content.decode(<span class="string">&#x27;utf-8&#x27;</span>)),na_values=[<span class="string">&#x27;NA&#x27;</span>,<span class="string">&#x27;?&#x27;</span>])</span><br><span class="line"></span><br><span class="line">cars = df[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">df.drop(<span class="string">&#x27;name&#x27;</span>,<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">missing_median(df, <span class="string">&#x27;horsepower&#x27;</span>)</span><br><span class="line">x,y = to_xy(df,<span class="string">&quot;mpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split into train/test</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(    </span><br><span class="line">    x, y, test_size=<span class="number">0.25</span>, random_state=<span class="number">45</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">10</span>, input_dim=x.shape[<span class="number">1</span>], kernel_initializer=<span class="string">&#x27;normal&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">&#x27;normal&#x27;</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mean_squared_error&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>)</span><br><span class="line"></span><br><span class="line">monitor = EarlyStopping(monitor=<span class="string">&#x27;val_loss&#x27;</span>, min_delta=<span class="number">1e-3</span>, patience=<span class="number">5</span>, verbose=<span class="number">1</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor],verbose=<span class="number">2</span>,epochs=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">Train on 398 samples, validate on 100 samples</span><br><span class="line">Epoch 1/1000</span><br><span class="line">0s - loss: 374.7638 - val_loss: 179.2396</span><br><span class="line">Epoch 2/1000</span><br><span class="line">0s - loss: 199.9990 - val_loss: 169.4834</span><br><span class="line">Epoch 3/1000</span><br><span class="line">0s - loss: 197.9431 - val_loss: 153.8338</span><br><span class="line">Epoch 4/1000</span><br><span class="line">0s - loss: 187.7644 - val_loss: 152.2758</span><br><span class="line">Epoch 5/1000</span><br><span class="line">0s - loss: 185.5505 - val_loss: 149.9817</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Epoch 179/1000</span><br><span class="line">0s - loss: 10.3191 - val_loss: 8.2763</span><br><span class="line">Epoch 180/1000</span><br><span class="line">0s - loss: 10.0629 - val_loss: 8.3435</span><br><span class="line">Epoch 181/1000</span><br><span class="line">0s - loss: 10.7124 - val_loss: 8.4712</span><br><span class="line">Epoch 182/1000</span><br><span class="line">0s - loss: 10.6406 - val_loss: 8.4272</span><br><span class="line">&lt;keras.callbacks.History at 0x222a8ecd1d0&gt;</span><br></pre></td></tr></table></figure>


<h2 id="Classification-Model-Early-Stop"><a href="#Classification-Model-Early-Stop" class="headerlink" title="Classification Model (Early Stop)"></a>Classification Model (Early Stop)</h2><p>Early stopping can also be used with classification.  Early stopping sets aside a part of the data to be used to validate the neural network.  The neural network is trained with the training data and validated with the validation data.  Once the error no longer improves on the validation set, the training stops.  This prevents the neural network from <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a>.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Activation</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"></span><br><span class="line">url=<span class="string">&quot;https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/data/iris.csv&quot;</span></span><br><span class="line">df=pd.read_csv(io.StringIO(requests.get(url).content.decode(<span class="string">&#x27;utf-8&#x27;</span>)),na_values=[<span class="string">&#x27;NA&#x27;</span>,<span class="string">&#x27;?&#x27;</span>])</span><br><span class="line"></span><br><span class="line">species = encode_text_index(df,<span class="string">&quot;species&quot;</span>)</span><br><span class="line">x,y = to_xy(df,<span class="string">&quot;species&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split into train/test</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(    </span><br><span class="line">    x, y, test_size=<span class="number">0.25</span>, random_state=<span class="number">45</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">10</span>, input_dim=x.shape[<span class="number">1</span>], kernel_initializer=<span class="string">&#x27;normal&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">&#x27;normal&#x27;</span>))</span><br><span class="line">model.add(Dense(y.shape[<span class="number">1</span>],activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>)</span><br><span class="line"></span><br><span class="line">monitor = EarlyStopping(monitor=<span class="string">&#x27;val_loss&#x27;</span>, min_delta=<span class="number">1e-3</span>, patience=<span class="number">5</span>, verbose=<span class="number">1</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor],verbose=<span class="number">2</span>,epochs=<span class="number">1000</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">Train on 150 samples, validate on 38 samples</span><br><span class="line">Epoch 1/1000</span><br><span class="line">0s - loss: 1.1095 - val_loss: 1.1143</span><br><span class="line">Epoch 2/1000</span><br><span class="line">0s - loss: 1.1065 - val_loss: 1.1096</span><br><span class="line">Epoch 3/1000</span><br><span class="line">0s - loss: 1.1041 - val_loss: 1.1057</span><br><span class="line">Epoch 4/1000</span><br><span class="line">0s - loss: 1.1020 - val_loss: 1.1038</span><br><span class="line">Epoch 5/1000</span><br><span class="line">0s - loss: 1.1011 - val_loss: 1.1017</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Epoch 325/1000</span><br><span class="line">0s - loss: 0.1758 - val_loss: 0.1320</span><br><span class="line">Epoch 326/1000</span><br><span class="line">0s - loss: 0.1755 - val_loss: 0.1332</span><br><span class="line">Epoch 00325: early stopping</span><br><span class="line">&lt;keras.callbacks.History at 0x222a9242d68&gt;</span><br></pre></td></tr></table></figure>

<p>Show the predictions (raw, probability of each class.)</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Print out the raw predictions. Because there are 3 species of iris, there are 3 columns.  The number in each column is</span></span><br><span class="line"><span class="comment"># the probability that the flower is that type of iris.</span></span><br><span class="line"></span><br><span class="line">np.set_printoptions(suppress=<span class="literal">True</span>)</span><br><span class="line">pred = model.predict(x_test)</span><br><span class="line"><span class="built_in">print</span>(pred[<span class="number">0</span>:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[[ 0.97540218  0.0245978   0.        ]</span><br><span class="line"> [ 0.94149685  0.05850318  0.        ]</span><br><span class="line"> [ 0.02133332  0.27963796  0.69902873]</span><br><span class="line"> [ 0.94382465  0.05617536  0.        ]</span><br><span class="line"> [ 0.95254719  0.04745276  0.        ]</span><br><span class="line"> [ 0.95966363  0.04033642  0.        ]</span><br><span class="line"> [ 0.94291645  0.05708356  0.        ]</span><br><span class="line"> [ 0.00293462  0.06093681  0.93612856]</span><br><span class="line"> [ 0.00873046  0.14257514  0.84869444]</span><br><span class="line"> [ 0.00293431  0.0609317   0.93613404]]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># The to_xy function represented the input in the same way.  Each row has only 1.0 value because each row is only one type</span></span><br><span class="line"><span class="comment"># of iris.  This is the training data, we KNOW what type of iris it is.  This is called one-hot encoding.  Only one value</span></span><br><span class="line"><span class="comment"># is 1.0 (hot)</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(y_test[<span class="number">0</span>:<span class="number">10</span>])</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[[ 1.  0.  0.]</span><br><span class="line"> [ 1.  0.  0.]</span><br><span class="line"> [ 0.  0.  1.]</span><br><span class="line"> [ 1.  0.  0.]</span><br><span class="line"> [ 1.  0.  0.]</span><br><span class="line"> [ 1.  0.  0.]</span><br><span class="line"> [ 1.  0.  0.]</span><br><span class="line"> [ 0.  0.  1.]</span><br><span class="line"> [ 0.  0.  1.]</span><br><span class="line"> [ 0.  0.  1.]]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> log_loss</span><br><span class="line"></span><br><span class="line"><span class="comment"># Using the predictions (pred) and the known 1-hot encodings (y_test) we can compute the log-loss error.  </span></span><br><span class="line"><span class="comment"># The lower a log loss the better.  The probabilities (pred) from the previous section specify how sure the neural network</span></span><br><span class="line"><span class="comment"># is of its prediction.  Log loss error pubishes the neural network (with a lower score) for very confident, but wrong,</span></span><br><span class="line"><span class="comment"># classifications.</span></span><br><span class="line"><span class="built_in">print</span>(log_loss(y_test,pred))</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">0.133210815783</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Usually the column (pred) with the highest prediction is considered to be the prediction of the neural network.  It is easy</span></span><br><span class="line"><span class="comment"># to convert the predictions to the expected iris species.  The argmax function finds the index of the maximum prediction</span></span><br><span class="line"><span class="comment"># for each row.</span></span><br><span class="line"></span><br><span class="line">predict_classes = np.argmax(pred,axis=<span class="number">1</span>)</span><br><span class="line">expected_classes = np.argmax(y_test,axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Predictions: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(predict_classes))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Expected: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(expected_classes))</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">Predictions: [0 0 2 0 0 0 0 2 2 2 0 2 2 2 2 0 2 2 0 1 1 1 2 1 0 2 1 1 0 1 1 1 2 2 0 2 0</span><br><span class="line"> 0]</span><br><span class="line">Expected: [0 0 2 0 0 0 0 2 2 2 0 2 2 2 2 0 2 2 0 1 1 1 2 1 0 2 1 1 0 1 1 1 2 2 0 2 0</span><br><span class="line"> 0]</span><br><span class="line"></span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Of course it is very easy to turn these indexes back into iris species.  We just use the species list that we created earlier.</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(species[predict_classes[<span class="number">1</span>:<span class="number">10</span>]])</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[&#x27;Iris-setosa&#x27; &#x27;Iris-virginica&#x27; &#x27;Iris-setosa&#x27; &#x27;Iris-setosa&#x27; &#x27;Iris-setosa&#x27;</span><br><span class="line"> &#x27;Iris-setosa&#x27; &#x27;Iris-virginica&#x27; &#x27;Iris-virginica&#x27; &#x27;Iris-virginica&#x27;]</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.metrics <span class="keyword">import</span> accuracy_score</span><br><span class="line"></span><br><span class="line"><span class="comment"># Accuracy might be a more easily understood error metric.  It is essentially a test score.  For all of the iris predictions,</span></span><br><span class="line"><span class="comment"># what percent were correct?  The downside is it does not consider how confident the neural network was in each prediction.</span></span><br><span class="line"></span><br><span class="line">correct = accuracy_score(expected_classes,predict_classes)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Accuracy: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(correct))</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy: 1.0</span><br></pre></td></tr></table></figure>

<h2 id="Deeper-Networks"><a href="#Deeper-Networks" class="headerlink" title="Deeper Networks"></a>Deeper Networks</h2><p>Keras makes it easy to add addition layers as shown here:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> keras.callbacks <span class="keyword">import</span> EarlyStopping</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> regularizers</span><br><span class="line"></span><br><span class="line">url=<span class="string">&quot;https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/data/auto-mpg.csv&quot;</span></span><br><span class="line">df=pd.read_csv(io.StringIO(requests.get(url).content.decode(<span class="string">&#x27;utf-8&#x27;</span>)),na_values=[<span class="string">&#x27;NA&#x27;</span>,<span class="string">&#x27;?&#x27;</span>])</span><br><span class="line"></span><br><span class="line">cars = df[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">df.drop(<span class="string">&#x27;name&#x27;</span>,<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">missing_median(df, <span class="string">&#x27;horsepower&#x27;</span>)</span><br><span class="line">x,y = to_xy(df,<span class="string">&quot;mpg&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Split into train/test</span></span><br><span class="line">x_train, x_test, y_train, y_test = train_test_split(    </span><br><span class="line">    x, y, test_size=<span class="number">0.25</span>, random_state=<span class="number">45</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">50</span>, input_dim=x.shape[<span class="number">1</span>], kernel_initializer=<span class="string">&#x27;normal&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.2</span>))</span><br><span class="line">model.add(Dense(<span class="number">25</span>, input_dim=x.shape[<span class="number">1</span>], kernel_initializer=<span class="string">&#x27;normal&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">10</span>, input_dim=<span class="number">64</span>,</span><br><span class="line">                kernel_regularizer=regularizers.l2(<span class="number">0.01</span>),</span><br><span class="line">                activity_regularizer=regularizers.l1(<span class="number">0.01</span>),activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">&#x27;normal&#x27;</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mean_squared_error&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>)</span><br><span class="line"></span><br><span class="line">monitor = EarlyStopping(monitor=<span class="string">&#x27;val_loss&#x27;</span>, min_delta=<span class="number">1e-3</span>, patience=<span class="number">5</span>, verbose=<span class="number">1</span>, mode=<span class="string">&#x27;auto&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model.fit(x,y,validation_data=(x_test,y_test),callbacks=[monitor],verbose=<span class="number">0</span>,epochs=<span class="number">1000</span>)</span><br><span class="line">pred = model.predict(x_test)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Measure RMSE error.  RMSE is common for regression.</span></span><br><span class="line">score = np.sqrt(metrics.mean_squared_error(pred,y_test))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Final score (RMSE): &#123;&#125;&quot;</span>.<span class="built_in">format</span>(score))</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Epoch 00064: early stopping</span><br><span class="line">Final score (RMSE): 4.421816825866699</span><br></pre></td></tr></table></figure>


<h2 id="The-Classic-MNIST-Dataset"><a href="#The-Classic-MNIST-Dataset" class="headerlink" title="The Classic MNIST Dataset"></a>The Classic MNIST Dataset</h2><p>The next examples will use the <a target="_blank" rel="noopener" href="http://yann.lecun.com/exdb/mnist/">MNIST digits dataset</a>.  The previous examples used CSV files to load training data.  Most neural network frameworks, such as Keras, have common training sets built in.  This makes it easy to run the example, but hard to abstract the example to your own data.  Your on data are not likely built into Keras.  However, the MNIST data is complex enough that it is beyond the scope of this article to discuss how to load it.  We will use the MNIST data build into Keras.  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line">(x_train, y_train), (x_test, y_test) = mnist.load_data()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape of x_train: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(x_train.shape))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape of y_train: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(y_train.shape))</span><br><span class="line"><span class="built_in">print</span>()</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape of x_test: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(x_test.shape))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Shape of y_test: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(y_test.shape))</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Shape of x_train: (60000, 28, 28)</span><br><span class="line">Shape of y_train: (60000,)</span><br><span class="line"></span><br><span class="line">Shape of x_test: (10000, 28, 28)</span><br><span class="line">Shape of y_test: (10000,)</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Display as image</span></span><br><span class="line">%matplotlib inline</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">digit = <span class="number">101</span> <span class="comment"># Change to choose new digit</span></span><br><span class="line"></span><br><span class="line">a = x_train[digit]</span><br><span class="line">plt.imshow(a, cmap=<span class="string">&#x27;gray&#x27;</span>, interpolation=<span class="string">&#x27;nearest&#x27;</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Image (#&#123;&#125;): Which is digit &#x27;&#123;&#125;&#x27;&quot;</span>.<span class="built_in">format</span>(digit,y_train[digit]))</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Image (#101): Which is digit &#x27;7&#x27;</span><br></pre></td></tr></table></figure>


<p><img src="/images/content/keras_mnist_7.png" alt="png"></p>
<h2 id="Convolutional-Neural-Networks"><a href="#Convolutional-Neural-Networks" class="headerlink" title="Convolutional Neural Networks"></a>Convolutional Neural Networks</h2><p>Convolutional Neural Networks are specifically for images.  They have been applied to other cases; however, use beyond images is somewhat rarer than with images.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> keras</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> mnist</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Dropout, Flatten</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"></span><br><span class="line">batch_size = <span class="number">128</span></span><br><span class="line">num_classes = <span class="number">10</span></span><br><span class="line">epochs = <span class="number">12</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># input image dimensions</span></span><br><span class="line">img_rows, img_cols = <span class="number">28</span>, <span class="number">28</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> K.image_data_format() == <span class="string">&#x27;channels_first&#x27;</span>:</span><br><span class="line">    x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">    x_test = x_test.reshape(x_test.shape[<span class="number">0</span>], <span class="number">1</span>, img_rows, img_cols)</span><br><span class="line">    input_shape = (<span class="number">1</span>, img_rows, img_cols)</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    x_train = x_train.reshape(x_train.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">    x_test = x_test.reshape(x_test.shape[<span class="number">0</span>], img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line">    input_shape = (img_rows, img_cols, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">x_train = x_train.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x_test = x_test.astype(<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">x_train /= <span class="number">255</span></span><br><span class="line">x_test /= <span class="number">255</span></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;x_train shape:&#x27;</span>, x_train.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Training samples: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(x_train.shape[<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test samples: &#123;&#125;&quot;</span>.<span class="built_in">format</span>(x_test.shape[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line"><span class="comment"># convert class vectors to binary class matrices</span></span><br><span class="line">y_train = keras.utils.to_categorical(y_train, num_classes)</span><br><span class="line">y_test = keras.utils.to_categorical(y_test, num_classes)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Conv2D(<span class="number">32</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>),</span><br><span class="line">                 activation=<span class="string">&#x27;relu&#x27;</span>,</span><br><span class="line">                 input_shape=input_shape))</span><br><span class="line">model.add(Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(MaxPooling2D(pool_size=(<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(Dropout(<span class="number">0.25</span>))</span><br><span class="line">model.add(Flatten())</span><br><span class="line">model.add(Dense(<span class="number">128</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(Dense(num_classes, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(loss=keras.losses.categorical_crossentropy,</span><br><span class="line">              optimizer=keras.optimizers.Adadelta(),</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line">model.fit(x_train, y_train,</span><br><span class="line">          batch_size=batch_size,</span><br><span class="line">          epochs=epochs,</span><br><span class="line">          verbose=<span class="number">2</span>,</span><br><span class="line">          validation_data=(x_test, y_test))</span><br><span class="line">score = model.evaluate(x_test, y_test, verbose=<span class="number">0</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Test loss: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(score[<span class="number">0</span>]))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Test accuracy: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(score[<span class="number">1</span>]))</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">x_train shape: (60000, 28, 28, 1)</span><br><span class="line">Training samples: 60000</span><br><span class="line">Test samples: 10000</span><br><span class="line">Train on 60000 samples, validate on 10000 samples</span><br><span class="line">Epoch 1/12</span><br><span class="line">271s - loss: 0.3435 - acc: 0.8950 - val_loss: 0.0817 - val_acc: 0.9755</span><br><span class="line">Epoch 2/12</span><br><span class="line">269s - loss: 0.1171 - acc: 0.9660 - val_loss: 0.0581 - val_acc: 0.9813</span><br><span class="line">Epoch 3/12</span><br><span class="line">458s - loss: 0.0885 - acc: 0.9742 - val_loss: 0.0453 - val_acc: 0.9859</span><br><span class="line">Epoch 4/12</span><br><span class="line">554s - loss: 0.0743 - acc: 0.9778 - val_loss: 0.0382 - val_acc: 0.9867</span><br><span class="line">Epoch 5/12</span><br><span class="line">261s - loss: 0.0642 - acc: 0.9810 - val_loss: 0.0346 - val_acc: 0.9887</span><br><span class="line">Epoch 6/12</span><br><span class="line">321s - loss: 0.0594 - acc: 0.9826 - val_loss: 0.0337 - val_acc: 0.9888</span><br><span class="line">Epoch 7/12</span><br><span class="line">309s - loss: 0.0515 - acc: 0.9846 - val_loss: 0.0335 - val_acc: 0.9890</span><br><span class="line">Epoch 8/12</span><br><span class="line">317s - loss: 0.0477 - acc: 0.9857 - val_loss: 0.0337 - val_acc: 0.9890</span><br><span class="line">Epoch 9/12</span><br><span class="line">308s - loss: 0.0448 - acc: 0.9870 - val_loss: 0.0330 - val_acc: 0.9889</span><br><span class="line">Epoch 10/12</span><br><span class="line">322s - loss: 0.0416 - acc: 0.9873 - val_loss: 0.0307 - val_acc: 0.9901</span><br><span class="line">Epoch 11/12</span><br><span class="line">326s - loss: 0.0394 - acc: 0.9879 - val_loss: 0.0300 - val_acc: 0.9899</span><br><span class="line">Epoch 12/12</span><br><span class="line">313s - loss: 0.0367 - acc: 0.9887 - val_loss: 0.0313 - val_acc: 0.9902</span><br><span class="line">Test loss: 0.03131893762472173</span><br><span class="line">Test accuracy: 0.9902</span><br></pre></td></tr></table></figure>


<h2 id="Long-Short-Term-Memory-LSTM"><a href="#Long-Short-Term-Memory-LSTM" class="headerlink" title="Long Short Term Memory (LSTM)"></a>Long Short Term Memory (LSTM)</h2><p>Long Short Term Memory is typically used for either time series or natural language processing (which can be thought of as a special case of natural language processing).</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing <span class="keyword">import</span> sequence</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Dense, Embedding</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> LSTM</span><br><span class="line"><span class="keyword">from</span> keras.datasets <span class="keyword">import</span> imdb</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line">max_features = <span class="number">4</span> <span class="comment"># 0,1,2,3 (total of 4)</span></span><br><span class="line">x = [</span><br><span class="line">    [[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">1</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>]],</span><br><span class="line">    [[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">2</span>],[<span class="number">2</span>],[<span class="number">0</span>]],</span><br><span class="line">    [[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">3</span>],[<span class="number">3</span>]],</span><br><span class="line">    [[<span class="number">0</span>],[<span class="number">2</span>],[<span class="number">2</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>]],</span><br><span class="line">    [[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">3</span>],[<span class="number">3</span>],[<span class="number">0</span>],[<span class="number">0</span>]],</span><br><span class="line">    [[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">0</span>],[<span class="number">1</span>],[<span class="number">1</span>]]</span><br><span class="line">]</span><br><span class="line">x = np.array(x,dtype=np.float32)</span><br><span class="line">y = np.array([<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">1</span>],dtype=np.int32)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Convert y2 to dummy variables</span></span><br><span class="line">y2 = np.zeros((y.shape[<span class="number">0</span>], max_features),dtype=np.float32)</span><br><span class="line">y2[np.arange(y.shape[<span class="number">0</span>]), y] = <span class="number">1.0</span></span><br><span class="line"><span class="built_in">print</span>(y2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Build model...&#x27;</span>)</span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(LSTM(<span class="number">128</span>, dropout=<span class="number">0.2</span>, recurrent_dropout=<span class="number">0.2</span>, input_dim=<span class="number">1</span>))</span><br><span class="line">model.add(Dense(<span class="number">4</span>, activation=<span class="string">&#x27;sigmoid&#x27;</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment"># try using different optimizers and different optimizer configs</span></span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;binary_crossentropy&#x27;</span>,</span><br><span class="line">              optimizer=<span class="string">&#x27;adam&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Train...&#x27;</span>)</span><br><span class="line">model.fit(x,y2,epochs=<span class="number">200</span>)</span><br><span class="line">pred = model.predict(x)</span><br><span class="line">predict_classes = np.argmax(pred,axis=<span class="number">1</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Predicted classes: &#123;&#125;&quot;</span>,predict_classes)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Expected classes: &#123;&#125;&quot;</span>,predict_classes)</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">[[ 0.  1.  0.  0.]</span><br><span class="line"> [ 0.  0.  1.  0.]</span><br><span class="line"> [ 0.  0.  0.  1.]</span><br><span class="line"> [ 0.  0.  1.  0.]</span><br><span class="line"> [ 0.  0.  0.  1.]</span><br><span class="line"> [ 0.  1.  0.  0.]]</span><br><span class="line">Build model...</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">c:\users\jeffh\anaconda3\envs\tf-latest\lib\site-packages\ipykernel\__main__.py:27: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.</span><br><span class="line">c:\users\jeffh\anaconda3\envs\tf-latest\lib\site-packages\ipykernel\__main__.py:27: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(128, input_shape=(None, 1), recurrent_dropout=0.2, dropout=0.2)`</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Train...</span><br><span class="line">Epoch 1/200</span><br><span class="line">6/6 [==============================] - 2s - loss: 0.7078 - acc: 0.5000</span><br><span class="line">Epoch 2/200</span><br><span class="line">6/6 [==============================] - 0s - loss: 0.7006 - acc: 0.5000</span><br><span class="line">Epoch 3/200</span><br><span class="line">6/6 [==============================] - 0s - loss: 0.6896 - acc: 0.6667</span><br><span class="line">Epoch 4/200</span><br><span class="line">6/6 [==============================] - 0s - loss: 0.6861 - acc: 0.6667</span><br><span class="line">Epoch 5/200</span><br><span class="line">6/6 [==============================] - 0s - loss: 0.6754 - acc: 0.7083</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Epoch 198/200</span><br><span class="line">6/6 [==============================] - 0s - loss: 0.2266 - acc: 0.9167</span><br><span class="line">Epoch 199/200</span><br><span class="line">6/6 [==============================] - 0s - loss: 0.2907 - acc: 0.8750</span><br><span class="line">Epoch 200/200</span><br><span class="line">6/6 [==============================] - 0s - loss: 0.1996 - acc: 0.9167</span><br><span class="line">Predicted classes: &#123;&#125; [1 2 3 2 3 1]</span><br><span class="line">Expected classes: &#123;&#125; [1 2 3 2 3 1]</span><br></pre></td></tr></table></figure>

<h2 id="Load-Save-a-Neural-Network"><a href="#Load-Save-a-Neural-Network" class="headerlink" title="Load/Save a Neural Network"></a>Load/Save a Neural Network</h2><p>It is very important to be able to load and save neural networks.  This allows your neural network to be used each time without retraining.</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> io</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">from</span> sklearn <span class="keyword">import</span> metrics</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Sequential</span><br><span class="line"><span class="keyword">from</span> keras.layers.core <span class="keyword">import</span> Dense, Activation</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"></span><br><span class="line">url=<span class="string">&quot;https://raw.githubusercontent.com/jeffheaton/t81_558_deep_learning/master/data/auto-mpg.csv&quot;</span></span><br><span class="line">df=pd.read_csv(io.StringIO(requests.get(url).content.decode(<span class="string">&#x27;utf-8&#x27;</span>)),na_values=[<span class="string">&#x27;NA&#x27;</span>,<span class="string">&#x27;?&#x27;</span>])</span><br><span class="line"></span><br><span class="line">cars = df[<span class="string">&#x27;name&#x27;</span>]</span><br><span class="line">df.drop(<span class="string">&#x27;name&#x27;</span>,<span class="number">1</span>,inplace=<span class="literal">True</span>)</span><br><span class="line">missing_median(df, <span class="string">&#x27;horsepower&#x27;</span>)</span><br><span class="line">x,y = to_xy(df,<span class="string">&quot;mpg&quot;</span>)</span><br><span class="line"></span><br><span class="line">model = Sequential()</span><br><span class="line">model.add(Dense(<span class="number">10</span>, input_dim=x.shape[<span class="number">1</span>], kernel_initializer=<span class="string">&#x27;normal&#x27;</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(Dense(<span class="number">1</span>, kernel_initializer=<span class="string">&#x27;normal&#x27;</span>))</span><br><span class="line">model.<span class="built_in">compile</span>(loss=<span class="string">&#x27;mean_squared_error&#x27;</span>, optimizer=<span class="string">&#x27;adam&#x27;</span>)</span><br><span class="line"></span><br><span class="line">model.fit(x,y,verbose=<span class="number">2</span>,epochs=<span class="number">100</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Epoch 1/100</span><br><span class="line">0s - loss: 188.3123</span><br><span class="line">Epoch 2/100</span><br><span class="line">0s - loss: 180.3333</span><br><span class="line">Epoch 3/100</span><br><span class="line">0s - loss: 177.1118</span><br><span class="line">Epoch 4/100</span><br><span class="line">0s - loss: 173.3682</span><br><span class="line">Epoch 5/100</span><br><span class="line">0s - loss: 167.0144</span><br><span class="line"></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line">Epoch 98/100</span><br><span class="line">0s - loss: 11.2297</span><br><span class="line">Epoch 99/100</span><br><span class="line">0s - loss: 11.0280</span><br><span class="line">Epoch 100/100</span><br><span class="line">0s - loss: 10.9314</span><br></pre></td></tr></table></figure>



<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">pred = model.predict(x)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Measure RMSE error.  RMSE is common for regression.</span></span><br><span class="line">score = np.sqrt(metrics.mean_squared_error(pred,y))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Before save score (RMSE): &#123;&#125;&quot;</span>.<span class="built_in">format</span>(score))</span><br><span class="line"></span><br><span class="line"><span class="comment"># save neural network structure to JSON (no weights)</span></span><br><span class="line">model_json = model.to_json()</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;network.json&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> json_file:</span><br><span class="line">    json_file.write(model_json)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save neural network structure to YAML (no weights)</span></span><br><span class="line">model_yaml = model.to_yaml()</span><br><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;network.yaml&quot;</span>, <span class="string">&quot;w&quot;</span>) <span class="keyword">as</span> yaml_file:</span><br><span class="line">    yaml_file.write(model_yaml)</span><br><span class="line"></span><br><span class="line"><span class="comment"># save entire network to HDF5 (save everything, suggested)</span></span><br><span class="line">model.save(<span class="string">&quot;network.h5&quot;</span>)</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Before save score (RMSE): 3.276093006134033</span><br></pre></td></tr></table></figure>


<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> load_model</span><br><span class="line"></span><br><span class="line">model2 = load_model(<span class="string">&#x27;network.h5&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Measure RMSE error.  RMSE is common for regression.</span></span><br><span class="line">score = np.sqrt(metrics.mean_squared_error(pred,y))</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;After load score (RMSE): &#123;&#125;&quot;</span>.<span class="built_in">format</span>(score))</span><br></pre></td></tr></table></figure>
<figure class="highlight console"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">After load score (RMSE): 3.276093006134033</span><br></pre></td></tr></table></figure>

      
    </div>

    
      

    

    <footer class="article-footer">
      <a data-url="https://www.heatonresearch.com/2017/07/22/keras-getting-started.html" data-id="cm659mycr003398mteiwsgf1z" class="article-share-link">
        <i class="fa fa-share"></i> Share
      </a>
      
        <a href="https://www.heatonresearch.com/2017/07/22/keras-getting-started.html#disqus_thread" class="article-comment-link">
          <i class="fa fa-comment"></i> Comments
        </a>
      
      

    </footer>
  </div>
  
    
<ul id="article-nav" class="nav nav-pills nav-justified">
  
  <li role="presentation">
    <a href="/jeffheaton-toolset.html" id="article-nav-older" class="article-nav-link-wrap">
      <i class="fa fa-chevron-left pull-left"></i>
      <span class="article-nav-link-title">My Current Software Toolkit</span>
    </a>
  </li>
  
  
  <li role="presentation">
    <a href="/2017/07/30/tensors.html" id="article-nav-newer" class="article-nav-link-wrap">
      <span class="article-nav-link-title">What are Tensors and why are they Flowing? (TensorFlow)</span>
      <i class="fa fa-chevron-right pull-right"></i>
    </a>
  </li>
  
</ul>


  
</article>


<section id="comments">
  <div id="disqus_thread">
    <noscript>Please enable JavaScript to view the <a target="_blank" rel="noopener" href="//disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
  </div>
</section>


    </div>
    <div class="col-sm-3 col-sm-offset-1 blog-sidebar">
      
  <div class="sidebar-module sidebar-module-inset">
  <h4>About</h4>
  <p>Jeff Heaton, Ph.D. is a YouTuber, [computer/data] [scientist/engineer], and indie publisher. Heaton Research is the homepage for his projects and research.</p>

</div>


  
  <div class="sidebar-module">
    <h4>Categories</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/ai/">ai</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/aifh/">aifh</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/bbs/">bbs</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/course/">course</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/datascience/">datascience</a><span class="sidebar-module-list-count">11</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/encog/">encog</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/gpu/">gpu</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/java/">java</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/kaggle/">kaggle</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/learning/">learning</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/mergelife/">mergelife</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/phd/">phd</a><span class="sidebar-module-list-count">7</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/presentation/">presentation</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/python/">python</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/r/">r</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/tensorflow/">tensorflow</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/categories/wustl/">wustl</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  


  

  
  <div class="sidebar-module">
    <h4>Archives</h4>
    <ul class="sidebar-module-list"><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/09/">September 2019</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/05/">May 2019</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2019/03/">March 2019</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/12/">December 2018</a><span class="sidebar-module-list-count">6</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/11/">November 2018</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/10/">October 2018</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/09/">September 2018</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/08/">August 2018</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2018/01/">January 2018</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/11/">November 2017</a><span class="sidebar-module-list-count">3</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/09/">September 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/08/">August 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/07/">July 2017</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/06/">June 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/05/">May 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/03/">March 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/02/">February 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2017/01/">January 2017</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/09/">September 2016</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/03/">March 2016</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2016/02/">February 2016</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2015/09/">September 2015</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2015/08/">August 2015</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2015/05/">May 2015</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2015/03/">March 2015</a><span class="sidebar-module-list-count">4</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2014/12/">December 2014</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2014/09/">September 2014</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2014/05/">May 2014</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2014/02/">February 2014</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2013/08/">August 2013</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2013/07/">July 2013</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2013/06/">June 2013</a><span class="sidebar-module-list-count">2</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2013/04/">April 2013</a><span class="sidebar-module-list-count">1</span></li><li class="sidebar-module-list-item"><a class="sidebar-module-list-link" href="/archives/2013/03/">March 2013</a><span class="sidebar-module-list-count">1</span></li></ul>
  </div>



  
  <div class="sidebar-module">
    <h4>Recents</h4>
    <ul class="sidebar-module-list">
      
        <li>
          <a href="/2019/09/09/pas-2019-features.html">Session 16: B/I - Multivariate Feature Engineering: Beyond Simple Data Preparation</a>
        </li>
      
        <li>
          <a href="/2019/09/03/tf-no-module-jupyter.html">Why am I getting ImportError: No module named tensorflow?</a>
        </li>
      
        <li>
          <a href="/2019/05/20/2019-video-schedule.html">Video Release Schedule for Fall 2019 Applications of Deep Learning</a>
        </li>
      
        <li>
          <a href="/2019/03/13/tensorflow_20_articles.html">My Favorite TensorFlow 2.0 Articles (as of March 2019)</a>
        </li>
      
        <li>
          <a href="/2018/12/26/youtube-2018-12-26-mergelife-timelapse.html">Time Lapse: Creating Several MergeLife Cellular Automata Online with JavaScript</a>
        </li>
      
    </ul>
  </div>



    </div>
</div>

  </div>
  <footer class="blog-footer">
  <div class="container">
    <div id="footer-info" class="inner">
      &copy; 2025 by Heaton Research, Inc. - <a href="/legal/">Legal and Copyright Info</a><br>
Jeff Heaton is a computer scientist, data scientist, and indie publisher. Heaton Research is the homepage for his projects and research. <a href="/tips.html">Tips and support.</a><br><br>
<ul class="list-inline banner-social-buttons">
  <li><a class="btn btn-default btn-sm" target="_blank" rel="noopener" href="https://github.com/jeffheaton"><i class="fa fa-github"> <span class="network-name">GitHub</span></i></a></li>
  <li><a class="btn btn-default btn-sm" target="_blank" rel="noopener" href="https://twitter.com/jeffheaton"><i class="fa fa-twitter"> <span class="network-name">Twitter</span></i></a></li>
  <li><a class="btn btn-default btn-sm" target="_blank" rel="noopener" href="https://www.youtube.com/user/HeatonResearch"><i class="fa fa-youtube-play"> <span class="network-name">Youtube</span></i></a></li>
  <li><a class="btn btn-default btn-sm" target="_blank" rel="noopener" href="https://www.facebook.com/encog.framework/"><i class="fa fa-facebook"> <span class="network-name">Facebook</span></i></a></li>
</ul>

    </div>
  </div>
</footer>

  
<script>
  var disqus_shortname = 'heatonresearch';
  
  var disqus_url = 'https://www.heatonresearch.com/2017/07/22/keras-getting-started.html';
  
  (function(){
    var dsq = document.createElement('script');
    dsq.type = 'text/javascript';
    dsq.async = true;
    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
  })();
</script>


<script src="https://ajax.googleapis.com/ajax/libs/jquery/2.1.4/jquery.min.js" integrity="sha384-8gBf6Y4YYq7Jx97PIqmTwLPin4hxIzQw5aDmUg/DDhul9fFpbbLcLh3nTIIDJKhx" crossorigin="anonymous"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.6/js/bootstrap.min.js" integrity="sha384-0mSbJDEHialfmuBBQP6A4Qrprq5OVfW37PRR3j5ELqxss1yVqOtnepnHVP9aJ7xS" crossorigin="anonymous"></script>









<script src="/js/script.js"></script><!-- hexo-inject:begin --><!-- hexo-inject:end -->


</body>
</html>
